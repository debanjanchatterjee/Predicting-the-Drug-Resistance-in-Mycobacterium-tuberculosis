{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PCA-NN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUp2OVqeLBrM"
      },
      "source": [
        "# Importing the librares"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EL8pelBLLt_"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import csv"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M3QQzQrK4JY"
      },
      "source": [
        "# Importing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-jNgcCEJRQn"
      },
      "source": [
        "#dataset = pd.read_csv('X_trainData_1.csv')\n",
        "#labels=pd.read_csv('Y_trainData_1.csv')\n",
        "dataset = pd.read_csv('X_trainData_column_modified_PCA_CAP.csv')\n",
        "datalabels=pd.read_csv('X_trainData_column_modified_CAP.csv')\n",
        "\n",
        "\n",
        "X_train=dataset.iloc[:,:].values\n",
        "#X_train=dataset.iloc[:,:-1].values\n",
        "y_train=datalabels.iloc[:,-1].values"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb8TObA8vGuc"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDM-TheaftrR",
        "outputId": "d6f3a524-a70c-4e28-987f-30c2f447a7f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(X_train)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.00000000e+00  1.07575094e+02 -1.90119808e+01 ...  1.67585513e-01\n",
            "  -1.60297759e-02 -2.52419486e-02]\n",
            " [ 2.00000000e+00  1.12747163e+02 -1.94524891e+01 ...  2.39257476e-01\n",
            "   7.85068934e-02 -3.99865137e-01]\n",
            " [ 3.00000000e+00  9.82537761e+01 -1.91011436e+01 ...  2.95889586e+00\n",
            "  -6.80896853e-01  2.05905530e-01]\n",
            " ...\n",
            " [ 1.33700000e+03  1.12481339e+02  4.59098368e+01 ... -7.63968245e-02\n",
            "  -3.91108815e-01 -3.47513066e-01]\n",
            " [ 1.33800000e+03  1.07273335e+02  4.20529961e+01 ... -1.24642162e+00\n",
            "  -6.49072096e-01  1.07213150e+00]\n",
            " [ 1.33900000e+03  1.12703974e+02  4.78657173e+01 ...  4.70730658e-02\n",
            "  -2.51965944e-01 -3.59163342e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "potB1vN5fxqI",
        "outputId": "13d88615-b3ca-46a0-e479-18949ee36f0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(y_train)\n",
        "\n",
        "count1=0\n",
        "count0=0\n",
        "\n",
        "for n in y_train:\n",
        "  if n==1:\n",
        "    count1=count1+1\n",
        "  else:\n",
        "    count0=count0+1\n",
        "\n",
        "print(count1)\n",
        "print(count0)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 0 ... 1 1 1]\n",
            "752\n",
            "587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un6aXeGQ-Bd2"
      },
      "source": [
        "# Building the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIg2QwfU-GhZ",
        "outputId": "be750c8a-53df-4987-97e1-a961988e9950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "ann = tf.keras.models.Sequential()\n",
        "\n",
        "#class_weight={1:1, 0:5}\n",
        "\n",
        "ann.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "\n",
        "ann.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "\n",
        "ann.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "\n",
        "ann.add(tf.keras.layers.Dense(units=12, activation='relu'))\n",
        "\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
        "\n",
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "ann.fit(X_train, y_train, batch_size = 16, epochs = 100)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.7097 - accuracy: 0.6161\n",
            "Epoch 2/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.8529\n",
            "Epoch 3/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2275 - accuracy: 0.9395\n",
            "Epoch 4/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9552\n",
            "Epoch 5/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0965 - accuracy: 0.9694\n",
            "Epoch 6/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.9798\n",
            "Epoch 7/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9664\n",
            "Epoch 8/100\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9791\n",
            "Epoch 9/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.9754\n",
            "Epoch 10/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9813\n",
            "Epoch 11/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 0.9888\n",
            "Epoch 12/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9910\n",
            "Epoch 13/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9940\n",
            "Epoch 14/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9933\n",
            "Epoch 15/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 0.9925\n",
            "Epoch 16/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 0.9918\n",
            "Epoch 17/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.9963\n",
            "Epoch 18/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 0.9970\n",
            "Epoch 19/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 0.9925\n",
            "Epoch 20/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9806\n",
            "Epoch 21/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0347 - accuracy: 0.9918\n",
            "Epoch 22/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.9970\n",
            "Epoch 23/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 0.9955\n",
            "Epoch 24/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 0.9955\n",
            "Epoch 25/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9963\n",
            "Epoch 26/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.9963\n",
            "Epoch 27/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 0.9970\n",
            "Epoch 28/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9955\n",
            "Epoch 29/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9963\n",
            "Epoch 30/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9970\n",
            "Epoch 31/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9970\n",
            "Epoch 32/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9970\n",
            "Epoch 33/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0281 - accuracy: 0.9910\n",
            "Epoch 34/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0795 - accuracy: 0.9798\n",
            "Epoch 35/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9873\n",
            "Epoch 36/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9866\n",
            "Epoch 37/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9925\n",
            "Epoch 38/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9955\n",
            "Epoch 39/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9970\n",
            "Epoch 40/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 0.9933\n",
            "Epoch 41/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9948\n",
            "Epoch 42/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9970\n",
            "Epoch 43/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9978\n",
            "Epoch 44/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9970\n",
            "Epoch 45/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9978\n",
            "Epoch 46/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.9903\n",
            "Epoch 47/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9970\n",
            "Epoch 48/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9970\n",
            "Epoch 49/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9970\n",
            "Epoch 50/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9940\n",
            "Epoch 51/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9970\n",
            "Epoch 52/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9963\n",
            "Epoch 53/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9978\n",
            "Epoch 54/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9970\n",
            "Epoch 55/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 0.9940\n",
            "Epoch 56/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9970\n",
            "Epoch 57/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 0.9933\n",
            "Epoch 58/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9866\n",
            "Epoch 59/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 0.9925\n",
            "Epoch 60/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9955\n",
            "Epoch 61/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9963\n",
            "Epoch 62/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9978\n",
            "Epoch 63/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.9963\n",
            "Epoch 64/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9925\n",
            "Epoch 65/100\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9940\n",
            "Epoch 66/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9978\n",
            "Epoch 67/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9978\n",
            "Epoch 68/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9978\n",
            "Epoch 69/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9963\n",
            "Epoch 70/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9955\n",
            "Epoch 71/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9978\n",
            "Epoch 72/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9978\n",
            "Epoch 73/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9978\n",
            "Epoch 74/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9978\n",
            "Epoch 75/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9978\n",
            "Epoch 76/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9978\n",
            "Epoch 77/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9978\n",
            "Epoch 78/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9978\n",
            "Epoch 79/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9978\n",
            "Epoch 80/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9978\n",
            "Epoch 81/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9963\n",
            "Epoch 82/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9978\n",
            "Epoch 83/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9978\n",
            "Epoch 84/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9978\n",
            "Epoch 85/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9978\n",
            "Epoch 86/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9978\n",
            "Epoch 87/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9978\n",
            "Epoch 88/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9978\n",
            "Epoch 89/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.9948\n",
            "Epoch 90/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9963\n",
            "Epoch 91/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9978\n",
            "Epoch 92/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9978\n",
            "Epoch 93/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9963\n",
            "Epoch 94/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 0.9948\n",
            "Epoch 95/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.9940\n",
            "Epoch 96/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 0.9910\n",
            "Epoch 97/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 0.9881\n",
            "Epoch 98/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9925\n",
            "Epoch 99/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9970\n",
            "Epoch 100/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f98402e6518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31FwZFBf4Vmk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ude1J0E47SKN",
        "outputId": "225fcaf7-9f23-4542-c23e-eaa4034fab66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#from xgboost import XGBClassifier\n",
        "#classifier = XGBClassifier()\n",
        "#classifier.fit(X_train, y_train)\n",
        "\n",
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "#classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
        "#classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='entropy', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
              "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04CKLTr894tv"
      },
      "source": [
        "#Predicting Validation set results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoHWkVPH1s_O",
        "outputId": "f9bd9c68-135a-4b5a-a228-2b29ed89d728",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "test_data = pd.read_csv('X_testData_column_modified_PCA_CAP.csv')\n",
        "#test_data = pd.read_csv('X_testData_1_modified.csv')\n",
        "\n",
        "X_test=test_data.iloc[:,:].values\n",
        "\n",
        "\n",
        "print(type(X_test))\n",
        "print(len(X_test))\n",
        "print(len(X_test[0]))\n",
        "print(X_test)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "501\n",
            "156\n",
            "[[ 1.00000000e+00  1.04826834e+02  4.12479709e+01 ... -1.66588102e+00\n",
            "   1.54536971e+00 -4.79476709e-01]\n",
            " [ 2.00000000e+00  1.09004854e+02  3.35838110e+01 ... -2.63355575e+00\n",
            "  -8.46839943e-01  1.31392004e+00]\n",
            " [ 3.00000000e+00  1.08294125e+02  4.06620371e+01 ... -9.06676587e-01\n",
            "   8.10714198e-01 -6.42887530e-01]\n",
            " ...\n",
            " [ 4.99000000e+02  1.11322786e+02  4.53693776e+01 ...  5.12968365e-01\n",
            "   6.96611427e-01  9.22126793e-01]\n",
            " [ 5.00000000e+02  1.10193302e+02  4.50443247e+01 ... -5.12303733e-01\n",
            "  -4.85042104e-01 -1.00620116e+00]\n",
            " [ 5.01000000e+02  1.11655703e+02  4.56392055e+01 ... -7.23516434e-01\n",
            "  -2.02709548e+00  1.35407658e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L4wXUSM987y",
        "outputId": "38c72dad-1283-4884-e9d2-9f8ab6ed2e0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#y_pred = classifier.predict_proba(X_test)\n",
        "#y_pred = classifier.predict(X_test)\n",
        "y_pred = ann.predict(X_test)\n",
        "print(y_pred)\n",
        "\n",
        "print(type(y_pred))\n",
        "#y_pred = (y_pred > 0.5)\n",
        "#print(np.concatenate((y_pred.reshape(len(y_pred),1), y_validation.reshape(len(y_validation),1)),1))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.9999987 ]\n",
            " [0.9982033 ]\n",
            " [0.9997336 ]\n",
            " [0.9995714 ]\n",
            " [0.9999753 ]\n",
            " [0.9997136 ]\n",
            " [0.9902367 ]\n",
            " [0.9996699 ]\n",
            " [0.9999261 ]\n",
            " [0.99997544]\n",
            " [0.99995947]\n",
            " [0.99974936]\n",
            " [0.99890125]\n",
            " [0.99910307]\n",
            " [0.9993344 ]\n",
            " [0.9941928 ]\n",
            " [0.9999995 ]\n",
            " [0.99756753]\n",
            " [0.99996984]\n",
            " [1.        ]\n",
            " [0.9999037 ]\n",
            " [0.9993969 ]\n",
            " [0.9999945 ]\n",
            " [0.9998254 ]\n",
            " [0.99981266]\n",
            " [0.99999964]\n",
            " [0.9999807 ]\n",
            " [0.9998252 ]\n",
            " [0.99802786]\n",
            " [0.9989786 ]\n",
            " [0.99996364]\n",
            " [0.99423826]\n",
            " [0.99778193]\n",
            " [0.9999889 ]\n",
            " [0.06945622]\n",
            " [0.99895775]\n",
            " [0.98730123]\n",
            " [0.999992  ]\n",
            " [0.9999429 ]\n",
            " [0.9991358 ]\n",
            " [0.9967848 ]\n",
            " [0.99973613]\n",
            " [0.99976426]\n",
            " [0.9999994 ]\n",
            " [0.9999527 ]\n",
            " [0.999572  ]\n",
            " [0.99988437]\n",
            " [0.99903095]\n",
            " [0.9992887 ]\n",
            " [0.99972814]\n",
            " [0.9999069 ]\n",
            " [0.99994004]\n",
            " [0.9997676 ]\n",
            " [0.9999931 ]\n",
            " [0.99998426]\n",
            " [0.9949157 ]\n",
            " [0.9999354 ]\n",
            " [0.9996512 ]\n",
            " [0.99880993]\n",
            " [0.999268  ]\n",
            " [0.9963003 ]\n",
            " [0.9994723 ]\n",
            " [0.99947995]\n",
            " [0.9999144 ]\n",
            " [0.9999999 ]\n",
            " [0.9987143 ]\n",
            " [0.9999174 ]\n",
            " [0.9981007 ]\n",
            " [0.99896944]\n",
            " [0.9937016 ]\n",
            " [0.99914324]\n",
            " [0.998968  ]\n",
            " [0.99997234]\n",
            " [0.9998871 ]\n",
            " [0.9995184 ]\n",
            " [0.99840444]\n",
            " [0.99956685]\n",
            " [0.9995907 ]\n",
            " [0.9992955 ]\n",
            " [0.9998876 ]\n",
            " [0.9993955 ]\n",
            " [0.9996352 ]\n",
            " [0.999912  ]\n",
            " [0.99982893]\n",
            " [0.9982911 ]\n",
            " [0.9998963 ]\n",
            " [0.99812335]\n",
            " [0.9952964 ]\n",
            " [1.        ]\n",
            " [0.9999877 ]\n",
            " [0.9930448 ]\n",
            " [0.99891865]\n",
            " [0.9992435 ]\n",
            " [0.99941814]\n",
            " [0.9972404 ]\n",
            " [0.9298653 ]\n",
            " [0.9993162 ]\n",
            " [0.9976291 ]\n",
            " [0.99999857]\n",
            " [0.999688  ]\n",
            " [0.9948002 ]\n",
            " [0.9998764 ]\n",
            " [0.9935342 ]\n",
            " [0.9994808 ]\n",
            " [0.98278254]\n",
            " [0.99828255]\n",
            " [0.99184096]\n",
            " [0.9925269 ]\n",
            " [0.99703133]\n",
            " [0.99997437]\n",
            " [0.99960774]\n",
            " [0.99566865]\n",
            " [0.99861777]\n",
            " [0.98992187]\n",
            " [0.995362  ]\n",
            " [0.9976497 ]\n",
            " [0.9827136 ]\n",
            " [0.997957  ]\n",
            " [0.98932296]\n",
            " [0.99836427]\n",
            " [0.06121985]\n",
            " [0.99989533]\n",
            " [0.9967884 ]\n",
            " [0.9726437 ]\n",
            " [0.99973196]\n",
            " [0.99173915]\n",
            " [0.6992728 ]\n",
            " [0.9976216 ]\n",
            " [0.9968098 ]\n",
            " [0.19976902]\n",
            " [0.99188906]\n",
            " [0.9997031 ]\n",
            " [0.98315156]\n",
            " [0.99675167]\n",
            " [0.99201584]\n",
            " [0.99203557]\n",
            " [0.999501  ]\n",
            " [0.9916822 ]\n",
            " [0.9994204 ]\n",
            " [0.997997  ]\n",
            " [0.99774534]\n",
            " [0.9999589 ]\n",
            " [0.9921266 ]\n",
            " [0.99921   ]\n",
            " [0.9998822 ]\n",
            " [0.9835594 ]\n",
            " [0.9972703 ]\n",
            " [0.9998554 ]\n",
            " [0.99985516]\n",
            " [0.9990871 ]\n",
            " [0.9988469 ]\n",
            " [0.99117625]\n",
            " [0.99983215]\n",
            " [0.99985003]\n",
            " [0.9998294 ]\n",
            " [0.9997061 ]\n",
            " [0.999871  ]\n",
            " [0.9848337 ]\n",
            " [0.9942484 ]\n",
            " [0.9995316 ]\n",
            " [0.9945775 ]\n",
            " [0.9977933 ]\n",
            " [0.9988825 ]\n",
            " [0.99995863]\n",
            " [0.99877673]\n",
            " [0.9872049 ]\n",
            " [0.9991867 ]\n",
            " [0.9997067 ]\n",
            " [0.99972767]\n",
            " [0.9975109 ]\n",
            " [0.992478  ]\n",
            " [0.99980825]\n",
            " [0.9996245 ]\n",
            " [0.99253535]\n",
            " [0.95651406]\n",
            " [0.99165523]\n",
            " [0.9960769 ]\n",
            " [0.16362174]\n",
            " [0.99909675]\n",
            " [0.99998486]\n",
            " [0.9993813 ]\n",
            " [0.99906665]\n",
            " [0.9988852 ]\n",
            " [0.99978393]\n",
            " [0.9969612 ]\n",
            " [0.98069227]\n",
            " [0.99694115]\n",
            " [0.9999883 ]\n",
            " [0.9998349 ]\n",
            " [0.9983771 ]\n",
            " [0.9801564 ]\n",
            " [0.9970866 ]\n",
            " [0.99784994]\n",
            " [0.9978381 ]\n",
            " [0.99911267]\n",
            " [0.94732624]\n",
            " [0.9984816 ]\n",
            " [0.9976801 ]\n",
            " [0.9973212 ]\n",
            " [0.9953341 ]\n",
            " [0.99761045]\n",
            " [0.99497604]\n",
            " [0.98481154]\n",
            " [0.99989223]\n",
            " [0.99990654]\n",
            " [0.9999157 ]\n",
            " [0.99977463]\n",
            " [0.6268317 ]\n",
            " [0.9999747 ]\n",
            " [0.99926096]\n",
            " [0.9982407 ]\n",
            " [0.27294275]\n",
            " [0.9999137 ]\n",
            " [0.9959869 ]\n",
            " [0.99965787]\n",
            " [0.99910384]\n",
            " [0.9820279 ]\n",
            " [0.9975988 ]\n",
            " [0.9829297 ]\n",
            " [0.9981584 ]\n",
            " [0.97856253]\n",
            " [0.99996793]\n",
            " [0.9855679 ]\n",
            " [0.98719984]\n",
            " [0.98153275]\n",
            " [0.9901759 ]\n",
            " [0.97413933]\n",
            " [0.9808883 ]\n",
            " [0.98190695]\n",
            " [0.98913866]\n",
            " [0.7507418 ]\n",
            " [0.9512882 ]\n",
            " [0.7938588 ]\n",
            " [0.98853827]\n",
            " [0.9999776 ]\n",
            " [0.9924932 ]\n",
            " [0.9982078 ]\n",
            " [0.8933935 ]\n",
            " [0.9960834 ]\n",
            " [0.39050543]\n",
            " [0.9990576 ]\n",
            " [0.97976696]\n",
            " [0.99594116]\n",
            " [0.9999958 ]\n",
            " [0.9940724 ]\n",
            " [0.9909734 ]\n",
            " [0.9829707 ]\n",
            " [0.9987746 ]\n",
            " [0.9999542 ]\n",
            " [0.99966455]\n",
            " [0.98436314]\n",
            " [0.9981558 ]\n",
            " [0.9990889 ]\n",
            " [0.9918601 ]\n",
            " [0.9995265 ]\n",
            " [0.99973065]\n",
            " [0.9911526 ]\n",
            " [0.99762315]\n",
            " [0.9996942 ]\n",
            " [0.97414726]\n",
            " [0.9896856 ]\n",
            " [0.999726  ]\n",
            " [0.9961712 ]\n",
            " [0.9987204 ]\n",
            " [0.9992324 ]\n",
            " [0.99924636]\n",
            " [0.9998067 ]\n",
            " [0.9998056 ]\n",
            " [0.9865791 ]\n",
            " [0.9973264 ]\n",
            " [0.99995947]\n",
            " [0.58038205]\n",
            " [0.9961637 ]\n",
            " [0.9982666 ]\n",
            " [0.99992037]\n",
            " [0.9962282 ]\n",
            " [0.9982272 ]\n",
            " [0.9972583 ]\n",
            " [0.9901216 ]\n",
            " [0.998728  ]\n",
            " [0.45413584]\n",
            " [0.9965922 ]\n",
            " [0.9993411 ]\n",
            " [0.9467423 ]\n",
            " [0.9987674 ]\n",
            " [0.99986255]\n",
            " [0.9835065 ]\n",
            " [0.46417007]\n",
            " [0.9999858 ]\n",
            " [0.9985661 ]\n",
            " [0.99932075]\n",
            " [0.99770254]\n",
            " [0.9988071 ]\n",
            " [0.96777457]\n",
            " [0.9787749 ]\n",
            " [0.9961738 ]\n",
            " [0.9769697 ]\n",
            " [0.9981487 ]\n",
            " [0.9936178 ]\n",
            " [0.9942478 ]\n",
            " [0.9644366 ]\n",
            " [0.998108  ]\n",
            " [0.7900977 ]\n",
            " [0.98025674]\n",
            " [0.9986559 ]\n",
            " [0.9786612 ]\n",
            " [0.9802263 ]\n",
            " [0.9995259 ]\n",
            " [0.99625564]\n",
            " [0.96995306]\n",
            " [0.9990784 ]\n",
            " [0.9964079 ]\n",
            " [0.97700727]\n",
            " [0.9863703 ]\n",
            " [0.9937529 ]\n",
            " [0.998252  ]\n",
            " [0.9319551 ]\n",
            " [0.99891007]\n",
            " [0.9994474 ]\n",
            " [0.9962967 ]\n",
            " [0.9673187 ]\n",
            " [0.9933367 ]\n",
            " [0.9988158 ]\n",
            " [0.9784581 ]\n",
            " [0.9690477 ]\n",
            " [0.9999262 ]\n",
            " [0.9998037 ]\n",
            " [0.99567324]\n",
            " [0.9987766 ]\n",
            " [0.9869904 ]\n",
            " [0.9959149 ]\n",
            " [0.9995127 ]\n",
            " [0.98486114]\n",
            " [0.9975546 ]\n",
            " [0.6774739 ]\n",
            " [0.99973184]\n",
            " [0.9987471 ]\n",
            " [0.8064583 ]\n",
            " [0.99729246]\n",
            " [0.99391186]\n",
            " [0.99333453]\n",
            " [0.99947995]\n",
            " [0.9962746 ]\n",
            " [0.99889874]\n",
            " [0.99875474]\n",
            " [0.9983014 ]\n",
            " [0.98415   ]\n",
            " [0.8516991 ]\n",
            " [0.96395344]\n",
            " [0.9638607 ]\n",
            " [0.9983058 ]\n",
            " [0.90831524]\n",
            " [0.9946075 ]\n",
            " [0.9725274 ]\n",
            " [0.9930473 ]\n",
            " [0.977572  ]\n",
            " [0.99737406]\n",
            " [0.7901911 ]\n",
            " [0.99683976]\n",
            " [0.9978726 ]\n",
            " [0.974127  ]\n",
            " [0.8275416 ]\n",
            " [0.99863905]\n",
            " [0.99347985]\n",
            " [0.97547066]\n",
            " [0.9754087 ]\n",
            " [0.8206168 ]\n",
            " [0.9933727 ]\n",
            " [0.97311413]\n",
            " [0.9948673 ]\n",
            " [0.99615955]\n",
            " [0.80518323]\n",
            " [0.9749706 ]\n",
            " [0.9942158 ]\n",
            " [0.97484404]\n",
            " [0.97477967]\n",
            " [0.98795134]\n",
            " [0.9746268 ]\n",
            " [0.99932456]\n",
            " [0.80466896]\n",
            " [0.8370313 ]\n",
            " [0.99586344]\n",
            " [0.83666533]\n",
            " [0.98251617]\n",
            " [0.98443735]\n",
            " [0.92693883]\n",
            " [0.9738815 ]\n",
            " [0.9619984 ]\n",
            " [0.99145657]\n",
            " [0.9913805 ]\n",
            " [0.9984577 ]\n",
            " [0.99712306]\n",
            " [0.9887158 ]\n",
            " [0.84491765]\n",
            " [0.9911533 ]\n",
            " [0.9729548 ]\n",
            " [0.9861079 ]\n",
            " [0.99949276]\n",
            " [0.98718566]\n",
            " [0.9724215 ]\n",
            " [0.9835746 ]\n",
            " [0.990704  ]\n",
            " [0.97205997]\n",
            " [0.99974674]\n",
            " [0.9926714 ]\n",
            " [0.99415815]\n",
            " [0.981649  ]\n",
            " [0.9926602 ]\n",
            " [0.95793587]\n",
            " [0.9923161 ]\n",
            " [0.9977139 ]\n",
            " [0.9799385 ]\n",
            " [0.99557894]\n",
            " [0.94380546]\n",
            " [0.02373616]\n",
            " [0.99328846]\n",
            " [0.9917754 ]\n",
            " [0.9967116 ]\n",
            " [0.9940205 ]\n",
            " [0.99952996]\n",
            " [0.98836654]\n",
            " [0.9939873 ]\n",
            " [0.9163208 ]\n",
            " [0.9453562 ]\n",
            " [0.9954209 ]\n",
            " [0.9977608 ]\n",
            " [0.98898554]\n",
            " [0.99897194]\n",
            " [0.9689792 ]\n",
            " [0.99606115]\n",
            " [0.9687191 ]\n",
            " [0.9927099 ]\n",
            " [0.99784875]\n",
            " [0.99867404]\n",
            " [0.9975841 ]\n",
            " [0.8597234 ]\n",
            " [0.86017376]\n",
            " [0.7045214 ]\n",
            " [0.99585706]\n",
            " [0.9852255 ]\n",
            " [0.99945146]\n",
            " [0.9196959 ]\n",
            " [0.967161  ]\n",
            " [0.9670565 ]\n",
            " [0.98713243]\n",
            " [0.998439  ]\n",
            " [0.99284923]\n",
            " [0.96663576]\n",
            " [0.96652704]\n",
            " [0.9090236 ]\n",
            " [0.9929219 ]\n",
            " [0.96626264]\n",
            " [0.9996972 ]\n",
            " [0.8979916 ]\n",
            " [0.793724  ]\n",
            " [0.9970771 ]\n",
            " [0.9999403 ]\n",
            " [0.9999962 ]\n",
            " [0.9987417 ]\n",
            " [0.8637926 ]\n",
            " [0.99999547]\n",
            " [0.9991404 ]\n",
            " [0.99857223]\n",
            " [0.99929273]\n",
            " [0.9956377 ]\n",
            " [0.9840284 ]\n",
            " [0.88917977]\n",
            " [0.99953353]\n",
            " [0.9994153 ]\n",
            " [0.98485017]\n",
            " [0.99888235]\n",
            " [0.9951958 ]\n",
            " [0.99707544]\n",
            " [0.9664334 ]\n",
            " [0.99153614]\n",
            " [0.90861547]\n",
            " [0.9744668 ]\n",
            " [0.9964573 ]\n",
            " [0.90803057]\n",
            " [0.99669206]\n",
            " [0.9945793 ]\n",
            " [0.9967235 ]\n",
            " [0.9994748 ]\n",
            " [0.9999863 ]\n",
            " [0.9643935 ]\n",
            " [0.9895504 ]\n",
            " [0.97315276]\n",
            " [0.84522843]\n",
            " [0.9994204 ]\n",
            " [0.9596371 ]\n",
            " [0.9924459 ]\n",
            " [0.99904376]\n",
            " [0.96021396]\n",
            " [0.9997191 ]\n",
            " [0.99766564]\n",
            " [0.97425246]\n",
            " [0.9995345 ]\n",
            " [0.9983645 ]\n",
            " [0.9955302 ]\n",
            " [0.99527115]\n",
            " [0.9927608 ]]\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-VlhXT5075B",
        "outputId": "b474822e-4b1a-416d-87a1-e2d2f0751941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(y_pred))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgwFIpIhCPlq",
        "outputId": "a132ba05-e7f9-4522-a0e4-5dd4f9f02429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "submission_data = pd.read_csv('Y_testData_1_nolabels_CAP.csv')\n",
        "\n",
        "ids=submission_data.iloc[:,:1].values\n",
        "result=list()\n",
        "k=0\n",
        "#print(ids)\n",
        "#print(y_pred[0])\n",
        "for i in ids:\n",
        "  #result.append([ i[0], y_pred[i[0]-1][0] ])\n",
        "  #result.append([ i[0], y_pred[i[0]-1][0] ])\n",
        "  result.append([ i[0], y_pred[k][0] ])\n",
        "  #result.append([ i[0], y_pred[k][1] ])\n",
        "  k=k+1\n",
        "  #print(y_pred[i[0]-1][0])\n",
        "  #print('.')\n",
        "\n",
        "result.insert(0, ['ID','CAP'])\n",
        "print(result)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['ID', 'CAP'], [1, 0.9999987], [2, 0.9982033], [3, 0.9997336], [4, 0.9995714], [5, 0.9999753], [6, 0.9997136], [7, 0.9902367], [8, 0.9996699], [9, 0.9999261], [10, 0.99997544], [11, 0.99995947], [12, 0.99974936], [13, 0.99890125], [14, 0.99910307], [15, 0.9993344], [16, 0.9941928], [17, 0.9999995], [18, 0.99756753], [19, 0.99996984], [20, 1.0], [21, 0.9999037], [22, 0.9993969], [23, 0.9999945], [24, 0.9998254], [25, 0.99981266], [26, 0.99999964], [27, 0.9999807], [28, 0.9998252], [29, 0.99802786], [30, 0.9989786], [31, 0.99996364], [32, 0.99423826], [33, 0.99778193], [34, 0.9999889], [35, 0.06945622], [36, 0.99895775], [37, 0.98730123], [38, 0.999992], [39, 0.9999429], [40, 0.9991358], [41, 0.9967848], [42, 0.99973613], [43, 0.99976426], [44, 0.9999994], [45, 0.9999527], [46, 0.999572], [47, 0.99988437], [48, 0.99903095], [49, 0.9992887], [50, 0.99972814], [51, 0.9999069], [52, 0.99994004], [53, 0.9997676], [54, 0.9999931], [55, 0.99998426], [56, 0.9949157], [57, 0.9999354], [58, 0.9996512], [59, 0.99880993], [60, 0.999268], [61, 0.9963003], [62, 0.9994723], [63, 0.99947995], [64, 0.9999144], [65, 0.9999999], [66, 0.9987143], [67, 0.9999174], [68, 0.9981007], [69, 0.99896944], [70, 0.9937016], [71, 0.99914324], [72, 0.998968], [73, 0.99997234], [74, 0.9998871], [75, 0.9995184], [76, 0.99840444], [77, 0.99956685], [78, 0.9995907], [79, 0.9992955], [80, 0.9998876], [81, 0.9993955], [82, 0.9996352], [83, 0.999912], [84, 0.99982893], [85, 0.9982911], [86, 0.9998963], [87, 0.99812335], [88, 0.9952964], [89, 1.0], [90, 0.9999877], [91, 0.9930448], [92, 0.99891865], [93, 0.9992435], [94, 0.99941814], [95, 0.9972404], [96, 0.9298653], [97, 0.9993162], [98, 0.9976291], [99, 0.99999857], [100, 0.999688], [101, 0.9948002], [102, 0.9998764], [103, 0.9935342], [104, 0.9994808], [105, 0.98278254], [106, 0.99828255], [107, 0.99184096], [108, 0.9925269], [109, 0.99703133], [110, 0.99997437], [111, 0.99960774], [112, 0.99566865], [113, 0.99861777], [114, 0.98992187], [115, 0.995362], [116, 0.9976497], [117, 0.9827136], [118, 0.997957], [119, 0.98932296], [120, 0.99836427], [121, 0.06121985], [122, 0.99989533], [123, 0.9967884], [124, 0.9726437], [125, 0.99973196], [126, 0.99173915], [127, 0.6992728], [128, 0.9976216], [129, 0.9968098], [130, 0.19976902], [131, 0.99188906], [132, 0.9997031], [133, 0.98315156], [134, 0.99675167], [135, 0.99201584], [136, 0.99203557], [137, 0.999501], [138, 0.9916822], [139, 0.9994204], [140, 0.997997], [141, 0.99774534], [142, 0.9999589], [143, 0.9921266], [144, 0.99921], [145, 0.9998822], [146, 0.9835594], [147, 0.9972703], [148, 0.9998554], [149, 0.99985516], [150, 0.9990871], [151, 0.9988469], [152, 0.99117625], [153, 0.99983215], [154, 0.99985003], [155, 0.9998294], [156, 0.9997061], [157, 0.999871], [158, 0.9848337], [159, 0.9942484], [160, 0.9995316], [161, 0.9945775], [162, 0.9977933], [163, 0.9988825], [164, 0.99995863], [165, 0.99877673], [166, 0.9872049], [167, 0.9991867], [168, 0.9997067], [169, 0.99972767], [170, 0.9975109], [171, 0.992478], [172, 0.99980825], [173, 0.9996245], [174, 0.99253535], [175, 0.95651406], [176, 0.99165523], [177, 0.9960769], [178, 0.16362174], [179, 0.99909675], [180, 0.99998486], [181, 0.9993813], [182, 0.99906665], [183, 0.9988852], [184, 0.99978393], [185, 0.9969612], [186, 0.98069227], [187, 0.99694115], [188, 0.9999883], [189, 0.9998349], [190, 0.9983771], [191, 0.9801564], [192, 0.9970866], [193, 0.99784994], [194, 0.9978381], [195, 0.99911267], [196, 0.94732624], [197, 0.9984816], [198, 0.9976801], [200, 0.9973212], [202, 0.9953341], [204, 0.99761045], [206, 0.99497604], [208, 0.98481154], [212, 0.99989223], [213, 0.99990654], [215, 0.9999157], [216, 0.99977463], [217, 0.6268317], [218, 0.9999747], [219, 0.99926096], [220, 0.9982407], [221, 0.27294275], [222, 0.9999137], [224, 0.9959869], [227, 0.99965787], [228, 0.99910384], [231, 0.9820279], [232, 0.9975988], [234, 0.9829297], [235, 0.9981584], [236, 0.97856253], [238, 0.99996793], [239, 0.9855679], [240, 0.98719984], [242, 0.98153275], [243, 0.9901759], [244, 0.97413933], [245, 0.9808883], [247, 0.98190695], [251, 0.98913866], [256, 0.7507418], [257, 0.9512882], [258, 0.7938588], [259, 0.98853827], [262, 0.9999776], [263, 0.9924932], [264, 0.9982078], [266, 0.8933935], [267, 0.9960834], [270, 0.39050543], [271, 0.9990576], [272, 0.97976696], [278, 0.99594116], [279, 0.9999958], [280, 0.9940724], [281, 0.9909734], [287, 0.9829707], [289, 0.9987746], [290, 0.9999542], [296, 0.99966455], [302, 0.98436314], [307, 0.9981558], [316, 0.9990889], [319, 0.9918601], [320, 0.9995265], [325, 0.99973065], [333, 0.9911526], [345, 0.99762315], [352, 0.9996942], [356, 0.97414726], [363, 0.9896856], [380, 0.999726], [381, 0.9961712], [388, 0.9987204], [392, 0.9992324], [398, 0.99924636], [413, 0.9998067], [422, 0.9998056], [431, 0.9865791], [455, 0.9973264], [467, 0.99995947], [483, 0.58038205], [485, 0.9961637], [488, 0.9982666], [498, 0.99992037], [503, 0.9962282], [510, 0.9982272], [524, 0.9972583], [543, 0.9901216], [549, 0.998728], [554, 0.45413584], [559, 0.9965922], [565, 0.9993411], [567, 0.9467423], [576, 0.9987674], [579, 0.99986255], [588, 0.9835065], [598, 0.46417007], [599, 0.9999858], [601, 0.9985661], [603, 0.99932075], [628, 0.99770254], [631, 0.9988071], [632, 0.96777457], [633, 0.9787749], [634, 0.9961738], [635, 0.9769697], [636, 0.9981487], [637, 0.9936178], [638, 0.9942478], [639, 0.9644366], [640, 0.998108], [641, 0.7900977], [642, 0.98025674], [643, 0.9986559], [644, 0.9786612], [645, 0.9802263], [646, 0.9995259], [647, 0.99625564], [648, 0.96995306], [649, 0.9990784], [650, 0.9964079], [651, 0.97700727], [652, 0.9863703], [653, 0.9937529], [654, 0.998252], [655, 0.9319551], [656, 0.99891007], [657, 0.9994474], [658, 0.9962967], [659, 0.9673187], [660, 0.9933367], [661, 0.9988158], [662, 0.9784581], [663, 0.9690477], [664, 0.9999262], [665, 0.9998037], [666, 0.99567324], [667, 0.9987766], [668, 0.9869904], [669, 0.9959149], [670, 0.9995127], [671, 0.98486114], [672, 0.9975546], [673, 0.6774739], [674, 0.99973184], [675, 0.9987471], [676, 0.8064583], [677, 0.99729246], [678, 0.99391186], [679, 0.99333453], [680, 0.99947995], [681, 0.9962746], [682, 0.99889874], [683, 0.99875474], [684, 0.9983014], [685, 0.98415], [686, 0.8516991], [687, 0.96395344], [688, 0.9638607], [689, 0.9983058], [692, 0.90831524], [693, 0.9946075], [694, 0.9725274], [695, 0.9930473], [696, 0.977572], [697, 0.99737406], [698, 0.7901911], [699, 0.99683976], [700, 0.9978726], [701, 0.974127], [702, 0.8275416], [703, 0.99863905], [704, 0.99347985], [705, 0.97547066], [706, 0.9754087], [707, 0.8206168], [708, 0.9933727], [709, 0.97311413], [710, 0.9948673], [711, 0.99615955], [712, 0.80518323], [713, 0.9749706], [714, 0.9942158], [715, 0.97484404], [716, 0.97477967], [717, 0.98795134], [718, 0.9746268], [719, 0.99932456], [720, 0.80466896], [721, 0.8370313], [722, 0.99586344], [723, 0.83666533], [724, 0.98251617], [725, 0.98443735], [726, 0.92693883], [727, 0.9738815], [728, 0.9619984], [729, 0.99145657], [730, 0.9913805], [731, 0.9984577], [732, 0.99712306], [733, 0.9887158], [734, 0.84491765], [735, 0.9911533], [736, 0.9729548], [737, 0.9861079], [738, 0.99949276], [739, 0.98718566], [740, 0.9724215], [741, 0.9835746], [742, 0.990704], [743, 0.97205997], [744, 0.99974674], [745, 0.9926714], [746, 0.99415815], [747, 0.981649], [748, 0.9926602], [749, 0.95793587], [750, 0.9923161], [751, 0.9977139], [752, 0.9799385], [753, 0.99557894], [754, 0.94380546], [755, 0.023736162], [756, 0.99328846], [757, 0.9917754], [758, 0.9967116], [759, 0.9940205], [760, 0.99952996], [761, 0.98836654], [762, 0.9939873], [763, 0.9163208], [764, 0.9453562], [765, 0.9954209], [766, 0.9977608], [767, 0.98898554], [768, 0.99897194], [769, 0.9689792], [770, 0.99606115], [771, 0.9687191], [772, 0.9927099], [773, 0.99784875], [774, 0.99867404], [775, 0.9975841], [776, 0.8597234], [777, 0.86017376], [778, 0.7045214], [779, 0.99585706], [780, 0.9852255], [781, 0.99945146], [782, 0.9196959], [783, 0.967161], [784, 0.9670565], [785, 0.98713243], [786, 0.998439], [787, 0.99284923], [788, 0.96663576], [789, 0.96652704], [790, 0.9090236], [791, 0.9929219], [792, 0.96626264], [805, 0.9996972], [809, 0.8979916], [816, 0.793724], [826, 0.9970771], [841, 0.9999403], [847, 0.9999962], [893, 0.9987417], [951, 0.8637926], [952, 0.99999547], [953, 0.9991404], [954, 0.99857223], [955, 0.99929273], [956, 0.9956377], [957, 0.9840284], [958, 0.88917977], [959, 0.99953353], [960, 0.9994153], [961, 0.98485017], [962, 0.99888235], [963, 0.9951958], [964, 0.99707544], [965, 0.9664334], [966, 0.99153614], [967, 0.90861547], [968, 0.9744668], [969, 0.9964573], [970, 0.90803057], [971, 0.99669206], [972, 0.9945793], [973, 0.9967235], [974, 0.9994748], [975, 0.9999863], [976, 0.9643935], [977, 0.9895504], [978, 0.97315276], [979, 0.84522843], [980, 0.9994204], [981, 0.9596371], [982, 0.9924459], [983, 0.99904376], [984, 0.96021396], [985, 0.9997191], [986, 0.99766564], [987, 0.97425246], [988, 0.9995345], [989, 0.9983645], [990, 0.9955302], [991, 0.99527115], [992, 0.9927608]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1zP-sxYFP46"
      },
      "source": [
        "file = open('CAP_result.csv', 'w+', newline ='') \n",
        "  \n",
        "# writing the data into the file \n",
        "with file:     \n",
        "    write = csv.writer(file) \n",
        "    write.writerows(result) "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa-vi0QM-LC9"
      },
      "source": [
        "# Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw5t7mVa-Phl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYyn2oDE3JmY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCCFSasG3XYt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE37sSMdzp-n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}